import os
import logging
import requests
import gzip
import shutil
import tarfile
import torch
import json
import threading
import time
import spacy
import psycopg2

from flask import Flask, request, jsonify, redirect, url_for, render_template
from flask_login import current_user, LoginManager, login_user, logout_user, login_required, UserMixin
from authlib.integrations.flask_client import OAuth
from flask_sqlalchemy import SQLAlchemy
from dotenv import load_dotenv
from transformers import AutoModelForSequenceClassification, AutoTokenizer

# ğŸ”¹ ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ (.env)
load_dotenv()

# ğŸ”¹ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æœ€é©åŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ¶é™ï¼‰
os.environ["HF_HOME"] = "./cache"
os.environ["TRANSFORMERS_CACHE"] = "./cache"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

torch.set_num_threads(1)  # ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’åˆ¶é™ã—ãƒ¡ãƒ¢ãƒªç¯€ç´„

# ğŸ”¹ ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.DEBUG)

# ğŸ”¹ SpaCy æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
logging.info("Loading SpaCy model (ja_core_news_sm)...")
nlp = spacy.load("ja_core_news_sm")
logging.info("SpaCy model loaded.")

# ğŸ”¹ Flask ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ
app = Flask(__name__)

# Flask-Loginã®è¨­å®š
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = "login"  # ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåã‚’æŒ‡å®š

class User(UserMixin):
    def __init__(self, id):
        self.id = id

@login_manager.user_loader
def load_user(user_id):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’IDã§ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    return User(user_id)

# âœ… current_user ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ä½¿ç”¨å¯èƒ½ã«ã™ã‚‹
@app.context_processor
def inject_user():
    return dict(current_user=current_user)

# ğŸ”¹ `offensive_words.json` ã®ãƒ‘ã‚¹
JSON_PATH = os.path.join(os.path.dirname(__file__), "offensive_words.json")

def load_offensive_words():
    """`offensive_words.json` ã‚’ãƒ­ãƒ¼ãƒ‰"""
    try:
        with open(JSON_PATH, "r", encoding="utf-8") as f:
            words_data = json.load(f)
        return words_data.get("words", []), words_data.get("phrases", [])
    except (FileNotFoundError, json.JSONDecodeError):
        return [], []

# âœ… `offensive_words.json` ã®åˆæœŸãƒ­ãƒ¼ãƒ‰
offensive_words, offensive_phrases = load_offensive_words()

# ğŸ”¹ é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
quantized_model = None
tokenizer = None

def load_model():
    """é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’1å›ã ã‘ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    global quantized_model, tokenizer

    if quantized_model is None or tokenizer is None:
        model_name = "prajjwal1/bert-tiny"

        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)

        # âœ… ãƒ¢ãƒ‡ãƒ«ã®é‡å­åŒ–
        quantized_model = torch.quantization.quantize_dynamic(
            model, {torch.nn.Linear}, dtype=torch.qint8
        )
        logging.info("âœ… ãƒ¢ãƒ‡ãƒ«é‡å­åŒ–å®Œäº†ï¼")

# ğŸ”¹ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
db_url = os.getenv("DATABASE_URL", "sqlite:///database.db")
app.config["SQLALCHEMY_DATABASE_URI"] = db_url
app.config["SQLALCHEMY_TRACK_MODIFICATIONS"] = False
db = SQLAlchemy(app)

class SearchHistory(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    query = db.Column(db.String(255), unique=True, nullable=False)
    count = db.Column(db.Integer, default=1)

    @staticmethod
    def add_or_increment(query):
        """æ¤œç´¢å±¥æ­´ã‚’DBã«è¿½åŠ ã™ã‚‹ or ã‚«ã‚¦ãƒ³ãƒˆã‚’å¢—ã‚„ã™"""
        search_entry = SearchHistory.query.filter_by(query=query).first()
        if search_entry:
            search_entry.count += 1
        else:
            search_entry = SearchHistory(query=query, count=1)
            db.session.add(search_entry)
        db.session.commit()

def update_offensive_words_from_search():
    """10å›ä»¥ä¸Šæ¤œç´¢ã•ã‚ŒãŸå˜èªã‚’ `offensive_words.json` ã«è¿½åŠ """
    threshold = 10
    words_to_add = db.session.query(SearchHistory).filter(SearchHistory.count >= threshold).all()

    try:
        with open(JSON_PATH, "r", encoding="utf-8") as f:
            words_data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        words_data = {"words": [], "phrases": []}

    existing_words = set(words_data["words"])

    for word_entry in words_to_add:
        if word_entry.query not in existing_words:
            words_data["words"].append(word_entry.query)

    with open(JSON_PATH, "w", encoding="utf-8") as f:
        json.dump(words_data, f, ensure_ascii=False, indent=4)

    logging.info("âœ… `offensive_words.json` ã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰Dropbox URLã‚’å–å¾—
DROPBOX_DIFFERENCE_URL = os.getenv("DROPBOX_DIFFERENCE_URL")
DROPBOX_MODEL_URL = os.getenv("DROPBOX_MODEL_URL")
DROPBOX_OFFENSIVE_WORDS_URL = os.getenv("DROPBOX_OFFENSIVE_WORDS_URL")

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)

def download_file(url, output_path):
    """
    Dropboxã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ±ç”¨é–¢æ•°ã€‚
    """
    try:
        if not url:
            raise ValueError(f"URLãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {output_path}")

        logging.info(f"Downloading file from {url} to {output_path}...")
        response = requests.get(url, stream=True)
        response.raise_for_status()

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã¿
        with open(output_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

        logging.info(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {output_path}")
        return output_path
    except Exception as e:
        logging.error(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•— ({output_path}): {e}")
        return None

def download_offensive_words():
    """
    `offensive_words.json` ã‚’Dropboxã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‚
    """
    output_path = os.path.join(os.path.dirname(__file__), "offensive_words.json")
    return download_file(DROPBOX_OFFENSIVE_WORDS_URL, output_path)

def download_difference_file():
    """
    `difference.txt.gz` ã‚’Dropboxã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‚
    """
    output_path = os.path.join(os.path.dirname(__file__), "scrape_scripts", "difference.txt.gz")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)  # ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆ
    return download_file(DROPBOX_DIFFERENCE_URL, output_path)

def download_model_file():
    """
    `model.safetensors.gz` ã‚’Dropboxã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‚
    """
    output_path = os.path.join(os.path.dirname(__file__), "models", "model.safetensors.gz")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)  # ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆ
    return download_file(DROPBOX_MODEL_URL, output_path)

# å®Ÿè¡Œä¾‹
if __name__ == "__main__":
    download_offensive_words()
    download_difference_file()
    download_model_file()

# ğŸ”¹ DBåˆæœŸåŒ–
with app.app_context():
    db.create_all()

# âœ… Render ã® Cronã‚¸ãƒ§ãƒ–ãŒæœ‰åŠ¹ãªã‚‰ 24æ™‚é–“ã”ã¨ã« `offensive_words.json` ã‚’æ›´æ–°
def scheduled_update():
    while True:
        update_offensive_words_from_search()
        time.sleep(86400)  # 24æ™‚é–“ã”ã¨

threading.Thread(target=scheduled_update, daemon=True).start()

# ğŸ”¹ Flaskãƒ«ãƒ¼ãƒˆ
@app.route("/")
def home():
    return render_template("index.html")

@app.route("/search", methods=["GET", "POST"])
@login_required
def search():
    global quantized_model, tokenizer
    load_model()

    if request.method == "POST":
        query = request.form.get("query", "").strip()
        if not query:
            return render_template("search.html", error="æ¤œç´¢ã‚¯ã‚¨ãƒªãŒç©ºã§ã™ã€‚")

        # âœ… æ¤œç´¢å±¥æ­´ã«ä¿å­˜
        SearchHistory.add_or_increment(query)

        try:
            inputs = tokenizer(query, max_length=128, truncation=True, padding="max_length", return_tensors="pt")
            with torch.no_grad():
                outputs = quantized_model(**inputs)
                predictions = torch.argmax(outputs.logits, dim=1).item()
            return render_template("result.html", result=f"åˆ¤å®šçµæœ: {predictions}")
        except Exception as e:
            logging.error(f"æ¤œç´¢å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return render_template("search.html", error="æ¤œç´¢å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

    return render_template("search.html")

@app.route("/quick_check", methods=["POST"])
@login_required
def quick_check():
    user_text = request.form.get("text", "")
    for word in offensive_words:
        if word in user_text:
            return jsonify({
                "result": f"ã“ã®æ–‡ç« ã«ã¯å•é¡ŒãŒã‚ã‚Šã¾ã™: '{word}' ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚",
                "caution": "æ³¨æ„: æ³•çš„åˆ¤æ–­ã‚’ä¸‹ã™ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å°‚é–€å®¶ã«ç›¸è«‡ã—ã¦ãã ã•ã„ã€‚"
            })
    return jsonify({"result": "ã“ã®æ–‡ç« ã¯å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚"})

@app.route("/terms")
@login_required
def show_terms():
    terms_content = "ã“ã“ã«åˆ©ç”¨è¦ç´„ã®å†…å®¹ã‚’è¨˜è¼‰ã—ã¾ã™ã€‚"
    return render_template("terms.html", terms_content=terms_content)

# ğŸ”¹ ã‚¢ãƒ—ãƒªèµ·å‹•
if __name__ == "__main__":
    load_model()
    app.run(debug=False, host="0.0.0.0", port=int(os.getenv("PORT", 8000)))
