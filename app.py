import os
import logging
import requests
import gzip
import shutil
import tarfile
import torch
import json
import threading
import time
import spacy
import psycopg2

from flask import Flask, request, jsonify, redirect, url_for, render_template, session
from flask_login import current_user, LoginManager, login_user, logout_user, login_required, UserMixin
from authlib.integrations.flask_client import OAuth
from flask_sqlalchemy import SQLAlchemy
from dotenv import load_dotenv
from transformers import AutoModelForSequenceClassification, AutoTokenizer

# ğŸ”¹ ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ (.env)
load_dotenv()

# ğŸ”¹ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æœ€é©åŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ¶é™ï¼‰
os.environ["HF_HOME"] = "./cache"
os.environ["TRANSFORMERS_CACHE"] = "./cache"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

torch.set_num_threads(1)  # ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’åˆ¶é™ã—ãƒ¡ãƒ¢ãƒªç¯€ç´„

# ğŸ”¹ ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.DEBUG)

# ğŸ”¹ SpaCy æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
logging.info("Loading SpaCy model (ja_core_news_sm)...")
nlp = spacy.load("ja_core_news_sm")
logging.info("SpaCy model loaded.")

# ğŸ”¹ Flask ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ
app = Flask(__name__)  # Flaskã‚¢ãƒ—ãƒªã‚’æœ€åˆã«å®šç¾©

# Flaskã®è¨­å®šï¼ˆã“ã®é †åºãŒé‡è¦ï¼‰
app.secret_key = os.getenv("SECRET_KEY", "default_secret_key")  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—

# OAuthã®è¨­å®š
oauth = OAuth(app)

# Google OAuth è¨­å®š
oauth.register(
    name="google",
    client_id=os.getenv("GOOGLE_CLIENT_ID"),
    client_secret=os.getenv("GOOGLE_CLIENT_SECRET"),
    authorize_url="https://accounts.google.com/o/oauth2/v2/auth",
    access_token_url="https://oauth2.googleapis.com/token",
    userinfo_endpoint="https://openidconnect.googleapis.com/v1/userinfo",
    client_kwargs={
        "scope": "openid email profile"
    }
)

# Twitter OAuth è¨­å®š
oauth.register(
    name="twitter",
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã‚€ï¼ˆå®Ÿéš›ã«ã¯TWITTER_CLIENT_ID, TWITTER_CLIENT_SECRETã‚’ã‚»ãƒƒãƒˆã™ã‚‹ï¼‰
    client_id=os.getenv("TWITTER_CLIENT_ID"),
    client_secret=os.getenv("TWITTER_CLIENT_SECRET"),
    
    # OAuth2.0 ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    authorize_url="https://twitter.com/i/oauth2/authorize",
    access_token_url="https://api.twitter.com/2/oauth2/token",
    api_base_url="https://api.twitter.com/2/",

    # ã©ã®ã‚¹ã‚³ãƒ¼ãƒ—ã‚’è¦æ±‚ã™ã‚‹ã‹ (è¦ã‚¢ãƒ—ãƒªè¨­å®šã«å¿œã˜ã¦å¤‰æ›´)
    client_kwargs={
        "scope": "tweet.read users.read offline.access"
    }
)

# Googleãƒ­ã‚°ã‚¤ãƒ³
@app.route("/login/google")
def login_google():
    redirect_uri = url_for("authorize_google", _external=True)
    return oauth.google.authorize_redirect(redirect_uri)

@app.route("/authorize/google")
def authorize_google():
    token = oauth.google.authorize_access_token()
    user_info = oauth.google.get("userinfo").json()
    user = User(id=user_info["email"])  # emailã‚’IDã¨ã—ã¦ä»®å®š
    login_user(user)
    return redirect("/")

# Twitterãƒ­ã‚°ã‚¤ãƒ³
@app.route("/login/twitter")
def login_twitter():
    redirect_uri = url_for("authorize_twitter", _external=True)
    return oauth.twitter.authorize_redirect(redirect_uri)

@app.route("/authorize/twitter")
def authorize_twitter():
    token = oauth.twitter.authorize_access_token()
    # v2ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’åˆ©ç”¨
    user_info = oauth.twitter.get("users/me?user.fields=username").json()

    # user_info ã®ä¾‹:
    # {
    #   "data": {
    #       "id": "123456789",
    #       "name": "John Smith",
    #       "username": "johnsmith"
    #   }
    # }
    # screen_nameç›¸å½“ã¯ "username" ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã‚ã‚‹

    username = user_info["data"]["username"]
    user = User(id=username)
    login_user(user)
    return redirect("/")

# Flask-Loginã®è¨­å®š
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = "login_google"  # Googleãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…é ˆã®å ´åˆ

class User(UserMixin):
    def __init__(self, id):
        self.id = id

@login_manager.user_loader
def load_user(user_id):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’IDã§ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    return User(user_id)

# âœ… current_user ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ä½¿ç”¨å¯èƒ½ã«ã™ã‚‹
@app.context_processor
def inject_user():
    return dict(current_user=current_user)

# ğŸ”¹ `offensive_words.json` ã®ãƒ‘ã‚¹
JSON_PATH = os.path.join(os.path.dirname(__file__), "offensive_words.json")

def load_offensive_words():
    """`offensive_words.json` ã‚’ãƒ­ãƒ¼ãƒ‰"""
    try:
        with open(JSON_PATH, "r", encoding="utf-8") as f:
            words_data = json.load(f)
        return words_data.get("words", []), words_data.get("phrases", [])
    except (FileNotFoundError, json.JSONDecodeError):
        return [], []

# âœ… `offensive_words.json` ã®åˆæœŸãƒ­ãƒ¼ãƒ‰
offensive_words, offensive_phrases = load_offensive_words()

# ğŸ”¹ é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
quantized_model = None
tokenizer = None

def load_model():
    """é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’1å›ã ã‘ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    global quantized_model, tokenizer

    if quantized_model is None or tokenizer is None:
        model_name = "prajjwal1/bert-tiny"

        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)

        # âœ… ãƒ¢ãƒ‡ãƒ«ã®é‡å­åŒ–
        quantized_model = torch.quantization.quantize_dynamic(
            model, {torch.nn.Linear}, dtype=torch.qint8
        )
        logging.info("âœ… ãƒ¢ãƒ‡ãƒ«é‡å­åŒ–å®Œäº†ï¼")

# ğŸ”¹ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
db_url = os.getenv("DATABASE_URL", "sqlite:///database.db")
app.config["SQLALCHEMY_DATABASE_URI"] = db_url
app.config["SQLALCHEMY_TRACK_MODIFICATIONS"] = False
db = SQLAlchemy(app)

class SearchHistory(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    query = db.Column(db.String(255), unique=True, nullable=False)
    count = db.Column(db.Integer, default=1)

    @staticmethod
    def add_or_increment(query):
        """æ¤œç´¢å±¥æ­´ã‚’DBã«è¿½åŠ ã™ã‚‹ or ã‚«ã‚¦ãƒ³ãƒˆã‚’å¢—ã‚„ã™"""
        search_entry = SearchHistory.query.filter_by(query=query).first()
        if search_entry:
            search_entry.count += 1
        else:
            search_entry = SearchHistory(query=query, count=1)
            db.session.add(search_entry)
        db.session.commit()

def update_offensive_words_from_search():
    """10å›ä»¥ä¸Šæ¤œç´¢ã•ã‚ŒãŸå˜èªã‚’ `offensive_words.json` ã«è¿½åŠ """
    threshold = 10
    words_to_add = db.session.query(SearchHistory).filter(SearchHistory.count >= threshold).all()

    try:
        with open(JSON_PATH, "r", encoding="utf-8") as f:
            words_data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        words_data = {"words": [], "phrases": []}

    existing_words = set(words_data["words"])

    for word_entry in words_to_add:
        if word_entry.query not in existing_words:
            words_data["words"].append(word_entry.query)

    with open(JSON_PATH, "w", encoding="utf-8") as f:
        json.dump(words_data, f, ensure_ascii=False, indent=4)

    logging.info("âœ… `offensive_words.json` ã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰Dropbox URLã‚’å–å¾—
DROPBOX_DIFFERENCE_URL = os.getenv("DROPBOX_DIFFERENCE_URL")
DROPBOX_MODEL_URL = os.getenv("DROPBOX_MODEL_URL")
DROPBOX_OFFENSIVE_WORDS_URL = os.getenv("DROPBOX_OFFENSIVE_WORDS_URL")

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)

def download_file(url, output_path):
    """
    Dropboxã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ±ç”¨é–¢æ•°ã€‚
    """
    try:
        if not url:
            raise ValueError(f"URLãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {output_path}")

        logging.info(f"Downloading file from {url} to {output_path}...")
        response = requests.get(url, stream=True)
        response.raise_for_status()

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã¿
        with open(output_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

        logging.info(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {output_path}")
        return output_path
    except Exception as e:
        logging.error(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•— ({output_path}): {e}")
        return None

def download_offensive_words():
    """
    `offensive_words.json` ã‚’Dropboxã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‚
    """
    output_path = os.path.join(os.path.dirname(__file__), "offensive_words.json")
    return download_file(DROPBOX_OFFENSIVE_WORDS_URL, output_path)

def download_difference_file():
    """
    `difference.txt.gz` ã‚’Dropboxã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‚
    """
    output_path = os.path.join(os.path.dirname(__file__), "scrape_scripts", "difference.txt.gz")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)  # ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆ
    return download_file(DROPBOX_DIFFERENCE_URL, output_path)

def download_model_file():
    """
    `model.safetensors.gz` ã‚’Dropboxã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‚
    """
    output_path = os.path.join(os.path.dirname(__file__), "models", "model.safetensors.gz")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)  # ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆ
    return download_file(DROPBOX_MODEL_URL, output_path)

# å®Ÿè¡Œä¾‹
if __name__ == "__main__":
    download_offensive_words()
    download_difference_file()
    download_model_file()

# ğŸ”¹ DBåˆæœŸåŒ–
with app.app_context():
    db.create_all()

# âœ… Render ã® Cronã‚¸ãƒ§ãƒ–ãŒæœ‰åŠ¹ãªã‚‰ 24æ™‚é–“ã”ã¨ã« `offensive_words.json` ã‚’æ›´æ–°
def scheduled_update():
    """å®šæœŸçš„ã« `offensive_words.json` ã‚’æ›´æ–°"""
    while True:
        with app.app_context():  # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
            update_offensive_words_from_search()
        time.sleep(86400)  # 24æ™‚é–“ã”ã¨

threading.Thread(target=scheduled_update, daemon=True).start()

# ğŸ”¹ Flaskãƒ«ãƒ¼ãƒˆ
@app.route("/")
def home():
    return render_template("index.html")

@app.route("/search", methods=["GET", "POST"])
@login_required
def search():
    global quantized_model, tokenizer
    load_model()

    if request.method == "POST":
        query = request.form.get("query", "").strip()
        if not query:
            return render_template("search.html", error="æ¤œç´¢ã‚¯ã‚¨ãƒªãŒç©ºã§ã™ã€‚")

        # âœ… æ¤œç´¢å±¥æ­´ã«ä¿å­˜
        SearchHistory.add_or_increment(query)

        try:
            inputs = tokenizer(query, max_length=128, truncation=True, padding="max_length", return_tensors="pt")
            with torch.no_grad():
                outputs = quantized_model(**inputs)
                predictions = torch.argmax(outputs.logits, dim=1).item()
            return render_template("result.html", result=f"åˆ¤å®šçµæœ: {predictions}")
        except Exception as e:
            logging.error(f"æ¤œç´¢å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return render_template("search.html", error="æ¤œç´¢å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

    return render_template("search.html")

@app.route("/quick_check", methods=["POST"])
@login_required
def quick_check():
    user_text = request.form.get("text", "")
    for word in offensive_words:
        if word in user_text:
            return jsonify({
                "result": f"ã“ã®æ–‡ç« ã«ã¯å•é¡ŒãŒã‚ã‚Šã¾ã™: '{word}' ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚",
                "caution": "æ³¨æ„: æ³•çš„åˆ¤æ–­ã‚’ä¸‹ã™ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å°‚é–€å®¶ã«ç›¸è«‡ã—ã¦ãã ã•ã„ã€‚"
            })
    return jsonify({"result": "ã“ã®æ–‡ç« ã¯å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚"})

@app.route("/terms")
def show_terms():
    try:
        TERMS_PATH = os.path.join(os.path.dirname(__file__), "terms.txt")
        with open(TERMS_PATH, "r", encoding="utf-8") as f:
            terms_content = f.read()
        return render_template("terms.html", terms_content=terms_content)
    except FileNotFoundError:
        logging.error("terms.txt ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return render_template("terms.html", terms_content="åˆ©ç”¨è¦ç´„ã¯ç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

@app.route("/logout")
def logout():
    logout_user()  # Flask-Loginã®ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ
    session.clear()  # Flaskã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã‚’ã‚¯ãƒªã‚¢ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    return redirect("/")

if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "update_offensive_words":
        # å®šæœŸå®Ÿè¡Œç”¨ã®ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
        with app.app_context():
            update_offensive_words_from_search()
            logging.info("âœ… å®šæœŸçš„ãª `offensive_words.json` ã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    else:
        # Flaskã‚¢ãƒ—ãƒªã‚’é€šå¸¸é€šã‚Šèµ·å‹•
        load_model()
        app.run(debug=False, host="0.0.0.0", port=int(os.getenv("PORT", 8000)))
